"use client";

import { motion, useInView } from "framer-motion";
import { useRef } from "react";
import { Container } from "@/components/ui/container";
import { Card } from "@/components/ui/card";

const mathConcepts = [
  {
    title: "Distributed Gradient Accumulation",
    formula: "âˆ‡L(Î¸) = (1/N) Î£áµ¢â‚Œâ‚á´º âˆ‡Láµ¢(Î¸) â‰ˆ (1/|B|) Î£â±¼âˆˆB âˆ‡Lâ±¼(Î¸)",
    description:
      "LorientAI implements ring-allreduce with gradient compression using Top-K sparsification where K = âŒˆÏÂ·dâŒ‰ for sparsity ratio Ï âˆˆ (0,1]. Error feedback accumulation ensures convergence: eâ‚œâ‚Šâ‚ = eâ‚œ + gâ‚œ - Compress(eâ‚œ + gâ‚œ)",
  },
  {
    title: "Adaptive Learning Rate Scheduling",
    formula: "Î·â‚œ = Î·â‚€ Â· min(tâ»â°Â·âµ, t Â· warmupâ»Â¹Â·âµ) Â· âˆš(1 - Î²â‚‚áµ—)/(1 - Î²â‚áµ—)",
    description:
      "Our scheduler combines linear warmup with inverse square root decay, modulated by Adam's bias correction terms. For large batch training, we apply LARS: Î·Ì‚â‚— = Î· Â· â€–wâ‚—â€–/(â€–âˆ‡L(wâ‚—)â€– + Î²â€–wâ‚—â€–) per layer l.",
  },
  {
    title: "Mixed-Precision Numerics",
    formula: "xÌƒ = clamp(âŒŠx/sâŒ‰, -2áµ‡â»Â¹, 2áµ‡â»Â¹-1) Â· s, where s = max(|x|)/(2áµ‡â»Â¹-1)",
    description:
      "BF16 master weights with FP8 forward pass (E4M3) and backward pass (E5M2). Loss scaling with dynamic exponent: scale = 2^k where k = argmax{2^k Â· â€–âˆ‡Lâ€–âˆ < FP16_MAX}.",
  },
  {
    title: "Tensor Parallelism Sharding",
    formula: "Y = GeLU(XAâ‚)Aâ‚‚ â†’ Y = GeLU(X[Aâ‚]á¶œáµ’Ë¡)Â·AllReduce([Aâ‚‚]Ê³áµ’Ê·)",
    description:
      "Column-parallel linear layers partition A âˆˆ â„áµˆË£áµ into [Aâ‚|Aâ‚‚|...|Aâ‚š] across P devices. For attention: Q,K,V heads distributed with Î£áµ¢ softmax(Qáµ¢Káµ¢áµ€/âˆšdâ‚–)Váµ¢ computed locally before all-gather.",
  },
];

const optimizationTheory = [
  {
    title: "Convergence Guarantees",
    content: `For L-smooth, Î¼-strongly convex objectives with SGD:

ğ”¼[â€–Î¸â‚œ - Î¸*â€–Â²] â‰¤ (1 - Î¼Î·)áµ—â€–Î¸â‚€ - Î¸*â€–Â² + Î·ÏƒÂ²/Î¼

Where ÏƒÂ² bounds gradient variance. Our adaptive batching maintains:
Var(Ä) = ÏƒÂ²/|B| â‰¤ ÎµÂ² âŸ¹ |B| â‰¥ ÏƒÂ²/ÎµÂ²

Critical batch size Bâ‚–áµ£áµ¢â‚œ = tr(Hâ»Â¹Î£)/â€–âˆ‡Lâ€–Â² determines scaling efficiency.`,
  },
  {
    title: "Second-Order Approximations",
    content: `Shampoo preconditioner for matrix parameter W âˆˆ â„áµË£â¿:

Lâ‚œ = (Î£â‚›â‚Œâ‚áµ— Gâ‚›Gâ‚›áµ€ + ÎµI)^(1/4) âˆˆ â„áµË£áµ
Râ‚œ = (Î£â‚›â‚Œâ‚áµ— Gâ‚›áµ€Gâ‚› + ÎµI)^(1/4) âˆˆ â„â¿Ë£â¿

Update: Wâ‚œâ‚Šâ‚ = Wâ‚œ - Î·Â·Lâ‚œâ»Â¹Gâ‚œRâ‚œâ»Â¹

Matrix roots computed via coupled Newton iteration:
Xâ‚–â‚Šâ‚ = Â½(Xâ‚– + Yâ‚–â»Â¹), Yâ‚–â‚Šâ‚ = Â½(Yâ‚– + Xâ‚–â»Â¹)`,
  },
  {
    title: "Attention Complexity Reduction",
    content: `Standard attention: O(nÂ²d) time, O(nÂ²) memory

Flash Attention tiling with block sizes Báµ£, Bá¶œ:
- Load Qáµ¢ âˆˆ â„^(Báµ£Ã—d), Kâ±¼,Vâ±¼ âˆˆ â„^(Bá¶œÃ—d) to SRAM
- Compute Sáµ¢â±¼ = Qáµ¢Kâ±¼áµ€ âˆˆ â„^(Báµ£Ã—Bá¶œ)
- Online softmax: máµ¢â±¼ = max(máµ¢,â±¼â‚‹â‚, rowmax(Sáµ¢â±¼))
- Rescale: â„“áµ¢â±¼ = e^(máµ¢,â±¼â‚‹â‚-máµ¢â±¼)â„“áµ¢,â±¼â‚‹â‚ + rowsum(e^(Sáµ¢â±¼-máµ¢â±¼))

IO complexity: O(nÂ²dÂ²/M) for SRAM size M.`,
  },
  {
    title: "Gradient Checkpointing Trade-offs",
    content: `Memory-compute Pareto frontier for transformer with L layers:

Standard: O(LÂ·nÂ·d) memory, O(1) recomputation
âˆšL checkpointing: O(âˆšLÂ·nÂ·d) memory, O(âˆšL) recomputation
Selective: checkpoint at layers {âŒŠiL/kâŒ‹ : i âˆˆ [k]}

Optimal k minimizes: T(k) = T_fwd(1 + (L-k)/k) + T_bwd
Subject to: M(k) = M_actÂ·k + M_param â‰¤ M_available

Our solver uses DP: V(l,m) = min over checkpoints c âˆˆ [l]`,
  },
];

const distributedSystems = [
  {
    title: "Pipeline Parallelism Scheduling",
    content: `1F1B (One Forward One Backward) steady state:

Microbatch latency: T_mb = (p-1)Â·(t_f + t_b) + t_f + t_b
Pipeline bubble ratio: Î² = (p-1)/(m + p - 1)

For p stages, m microbatches, minimize Î² subject to:
mÂ·(memory per microbatch) â‰¤ available memory

Interleaved schedule with v virtual stages:
Î²_interleaved = (p-1)/(mÂ·v + p - 1)

Zero Bubble scheduling eliminates Î² via:
- W (weight gradient) decoupled from B (activation gradient)
- Schedule: Fâ‚Fâ‚‚...Fâ‚šBâ‚Wâ‚Bâ‚‚Wâ‚‚...Bâ‚šWâ‚š`,
  },
  {
    title: "Communication Topology Optimization",
    content: `Ring AllReduce for N workers, message size M:

T_ring = 2(N-1)/N Â· (Î± + MÂ·Î²/N)

Where Î± = latency, Î² = inverse bandwidth.

For hierarchical networks (intra-node NVLink, inter-node IB):
T_hier = T_intra_reduce + T_inter_allreduce + T_intra_broadcast

Bandwidth-optimal 2D torus AllReduce:
T_2D = 2Â·(âˆšN - 1)Â·(Î± + MÂ·Î²/âˆšN)

LorientAI auto-selects: argmin_{topo} T_topo(N, M, Î±, Î²)`,
  },
  {
    title: "ZeRO Memory Optimization",
    content: `Memory per GPU for model with Î¨ parameters:

Stage 1 (Optimizer States): 4Î¨ + 12Î¨/N
Stage 2 (+ Gradients): 2Î¨ + (2 + 12)Î¨/N
Stage 3 (+ Parameters): 16Î¨/N

Communication overhead per step:
ZeRO-1: 0 extra (optimizer step local)
ZeRO-2: Î¨ Â· sizeof(grad) AllReduce â†’ Reduce-Scatter
ZeRO-3: 2 Â· AllGather(Î¨/N) per layer (fwd + bwd)

Partition granularity g trades memory vs communication:
Memory: Î¨Â·sizeof(param)/g per partition
Comm: O(g) AllGather calls per layer`,
  },
];

const transformerMath = [
  {
    title: "Rotary Position Embeddings",
    formula: `RÎ¸,m = [cos(mÎ¸â‚)  -sin(mÎ¸â‚)  0  ...
         sin(mÎ¸â‚)   cos(mÎ¸â‚)  0  ...
         0          0         cos(mÎ¸â‚‚) ...
         ...]`,
    description:
      "RoPE encodes position via rotation: (RÎ¸,mqâ‚˜)áµ€(RÎ¸,nkâ‚™) = qâ‚˜áµ€RÎ¸,n-mkâ‚™. Base frequency Î¸áµ¢ = 10000^(-2i/d). NTK-aware scaling: Î¸'áµ¢ = Î¸áµ¢ Â· Î±^(d/(d-2i)) for context extension factor Î±.",
  },
  {
    title: "Grouped Query Attention",
    formula: "Attention(Q, K, V) = softmax(QKáµ€/âˆšdâ‚– + M)V where K,V âˆˆ â„^(nÃ—dâ‚–/g)",
    description:
      "GQA with g groups: nâ‚• heads share nâ‚–áµ¥ = nâ‚•/g key-value heads. Memory: O(2Â·nÂ·d/g) vs O(2Â·nÂ·d) for MHA. Interpolation from MQA via mean pooling: K_gqa = mean(K_mha[gÂ·i:(g+1)Â·i]) per group.",
  },
  {
    title: "SwiGLU Activation",
    formula: "SwiGLU(x, W, V, b, c) = Swish(xW + b) âŠ— (xV + c)",
    description:
      "Where Swish(x) = xÂ·Ïƒ(Î²x) and Ïƒ is sigmoid. Hidden dim d_ff = âŒŠ(8/3Â·d_modelÂ·2/3)âŒ‹ rounded to multiple of 256 for tensor core alignment. Gradient: âˆ‚SwiGLU/âˆ‚x = Ïƒ'(Wx)âŠ—(Vx)Â·W + Swish(Wx)Â·V",
  },
  {
    title: "RMSNorm Numerical Stability",
    formula: "RMSNorm(x) = x/RMS(x) Â· Î³, where RMS(x) = âˆš(Î£xáµ¢Â²/d + Îµ)",
    description:
      "Backward pass: âˆ‚L/âˆ‚x = Î³/RMS(x)Â·(âˆ‚L/âˆ‚y - È³Â·mean(âˆ‚L/âˆ‚y âŠ™ y)). For mixed precision: compute RMS in FP32, cast to BF16 for multiply. Fused kernel: single pass with Welford's online variance.",
  },
];

export function Technical() {
  const ref = useRef(null);
  const isInView = useInView(ref, { once: true, margin: "-100px" });

  return (
    <section ref={ref} className="py-24 md:py-32 bg-background-secondary/30">
      <Container size="wide">
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={isInView ? { opacity: 1, y: 0 } : {}}
          transition={{ duration: 0.6 }}
          className="text-center mb-16"
        >
          <span className="text-sm font-medium uppercase tracking-wider text-accent mb-4 block">
            Technical Deep Dive
          </span>
          <h2 className="text-3xl md:text-4xl font-semibold tracking-tight mb-4">
            The <span className="gradient-text">Mathematics</span> Under the Hood
          </h2>
          <p className="text-foreground-muted text-lg max-w-3xl mx-auto">
            LorientAI abstracts complexityâ€”but we believe in transparency. Here&apos;s
            the rigorous foundation powering your training runs.
          </p>
        </motion.div>

        {/* Core Optimization */}
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={isInView ? { opacity: 1, y: 0 } : {}}
          transition={{ duration: 0.6, delay: 0.1 }}
          className="mb-16"
        >
          <h3 className="text-xl font-semibold mb-6 text-accent">
            Â§ Gradient Optimization & Numerical Methods
          </h3>
          <div className="grid md:grid-cols-2 gap-6">
            {mathConcepts.map((concept, index) => (
              <Card key={concept.title} hover className="h-full">
                <h4 className="font-semibold mb-3">{concept.title}</h4>
                <div className="bg-background/50 rounded-lg p-3 mb-3 overflow-x-auto">
                  <code className="text-sm text-highlight font-mono whitespace-pre">
                    {concept.formula}
                  </code>
                </div>
                <p className="text-sm text-foreground-muted leading-relaxed">
                  {concept.description}
                </p>
              </Card>
            ))}
          </div>
        </motion.div>

        {/* Optimization Theory */}
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={isInView ? { opacity: 1, y: 0 } : {}}
          transition={{ duration: 0.6, delay: 0.2 }}
          className="mb-16"
        >
          <h3 className="text-xl font-semibold mb-6 text-accent">
            Â§ Convergence Theory & Complexity Analysis
          </h3>
          <div className="grid md:grid-cols-2 gap-6">
            {optimizationTheory.map((item) => (
              <Card key={item.title} hover className="h-full">
                <h4 className="font-semibold mb-3">{item.title}</h4>
                <pre className="text-xs text-foreground-muted font-mono whitespace-pre-wrap leading-relaxed bg-background/50 rounded-lg p-4 overflow-x-auto">
                  {item.content}
                </pre>
              </Card>
            ))}
          </div>
        </motion.div>

        {/* Distributed Systems */}
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={isInView ? { opacity: 1, y: 0 } : {}}
          transition={{ duration: 0.6, delay: 0.3 }}
          className="mb-16"
        >
          <h3 className="text-xl font-semibold mb-6 text-accent">
            Â§ Distributed Systems & Communication Primitives
          </h3>
          <div className="grid lg:grid-cols-3 gap-6">
            {distributedSystems.map((item) => (
              <Card key={item.title} hover className="h-full">
                <h4 className="font-semibold mb-3">{item.title}</h4>
                <pre className="text-xs text-foreground-muted font-mono whitespace-pre-wrap leading-relaxed bg-background/50 rounded-lg p-4 overflow-x-auto">
                  {item.content}
                </pre>
              </Card>
            ))}
          </div>
        </motion.div>

        {/* Transformer Mathematics */}
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={isInView ? { opacity: 1, y: 0 } : {}}
          transition={{ duration: 0.6, delay: 0.4 }}
          className="mb-16"
        >
          <h3 className="text-xl font-semibold mb-6 text-accent">
            Â§ Transformer Architecture Primitives
          </h3>
          <div className="grid md:grid-cols-2 gap-6">
            {transformerMath.map((item) => (
              <Card key={item.title} hover className="h-full">
                <h4 className="font-semibold mb-3">{item.title}</h4>
                <div className="bg-background/50 rounded-lg p-3 mb-3 overflow-x-auto">
                  <code className="text-xs text-highlight font-mono whitespace-pre">
                    {item.formula}
                  </code>
                </div>
                <p className="text-sm text-foreground-muted leading-relaxed">
                  {item.description}
                </p>
              </Card>
            ))}
          </div>
        </motion.div>

        {/* Loss Landscape */}
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={isInView ? { opacity: 1, y: 0 } : {}}
          transition={{ duration: 0.6, delay: 0.5 }}
        >
          <Card className="bg-gradient-to-br from-background-secondary to-background-tertiary border-accent/20">
            <h3 className="text-xl font-semibold mb-4">
              Loss Landscape & Scaling Laws
            </h3>
            <div className="grid md:grid-cols-2 gap-8">
              <div>
                <h4 className="font-medium text-accent mb-2">Chinchilla Optimal Compute</h4>
                <pre className="text-xs text-foreground-muted font-mono whitespace-pre-wrap leading-relaxed mb-4">
{`Given compute budget C (in FLOPs):
N_opt âˆ C^0.5  (optimal parameters)
D_opt âˆ C^0.5  (optimal tokens)

Loss scaling: L(N,D) = E + A/N^Î± + B/D^Î²
Where Î± â‰ˆ 0.34, Î² â‰ˆ 0.28, E = irreducible loss

Compute-optimal: C = 6Â·NÂ·D (forward pass)
Including backward: C_total â‰ˆ 6Â·NÂ·DÂ·(1 + 2) = 18Â·NÂ·D`}
                </pre>
              </div>
              <div>
                <h4 className="font-medium text-accent mb-2">Î¼P Hyperparameter Transfer</h4>
                <pre className="text-xs text-foreground-muted font-mono whitespace-pre-wrap leading-relaxed">
{`Maximal Update Parametrization for width scaling:

Input weights:  W_in ~ N(0, 1/d_in)
Output weights: W_out ~ N(0, 1/d_model)
Attention logits: QKáµ€/d_head (not âˆšd_head)

Learning rate scaling:
  Î·_embed = Î·_base Â· m_width
  Î·_hidden = Î·_base
  Î·_output = Î·_base / m_width

Where m_width = d_model / d_base.
Enables HP transfer from 10M â†’ 10B params.`}
                </pre>
              </div>
            </div>
            <div className="mt-6 pt-6 border-t border-border">
              <h4 className="font-medium text-accent mb-2">Emergent Capabilities Phase Transitions</h4>
              <pre className="text-xs text-foreground-muted font-mono whitespace-pre-wrap leading-relaxed">
{`Capability emergence as function of compute C:

P(capability | C) = Ïƒ((log C - log C_crit) / Ï„)

Where C_crit = critical compute threshold, Ï„ = sharpness.

Sharp transitions occur when:
âˆ‚Â²L/âˆ‚CÂ² changes sign (loss curvature inflection)

Grokking dynamics: generalization after memorization
t_grok âˆ 1/(Î»_reg Â· |S_train|) for regularization Î»_reg

LorientAI monitors: â€–âˆ‡L_trainâ€–/â€–âˆ‡L_valâ€– ratio for emergence detection.`}
              </pre>
            </div>
          </Card>
        </motion.div>

        {/* Bottom note */}
        <motion.p
          initial={{ opacity: 0 }}
          animate={isInView ? { opacity: 1 } : {}}
          transition={{ duration: 0.6, delay: 0.6 }}
          className="text-center text-sm text-foreground-subtle mt-12"
        >
          All optimizations are applied automatically. You write{" "}
          <code className="text-accent">lorient.train()</code>â€”we handle the
          Hessian-vector products.
        </motion.p>
      </Container>
    </section>
  );
}
